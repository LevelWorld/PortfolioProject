{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dc3350-6e01-4ac2-9310-c6b1da45bb09",
   "metadata": {},
   "source": [
    "# Web Scraping project # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e785431-0194-45e5-b42c-aab8b67e2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this project is to download images from the website 'pngmart.com'. \n",
    "# This project was inspired by an upwork job purposal posted in Summer of 2020.\n",
    "# This project was completed on 8/18/2024, a website can have their structures changed overtime \n",
    "# thus this project would need to be update to reflect those changes, in order to continue to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475b420e-7db3-46a3-8e1b-8d6db968b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.pngmart.com/sitemap_index.xml'\n",
    "\n",
    "# Change this value to reflect the total number of images that you desire to be download to your device.\n",
    "# if you want a really large number of images please do not try collect them all at once, \n",
    "# most likely will be strenuous to the website and result in it crashing and/or banning your .\n",
    "max_number_of_images = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3686c24e-9c9b-43fe-8636-b1142dde515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1be3aa-11f3-465e-b048-0fef0865dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(link)\n",
    "\n",
    "xml = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f35b35-5242-4794-af75-c74ae3dac44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(xml,\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891971e1-6373-4a99-87f8-6604c3264997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pngmart.com/post-sitemap1.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25776/3425075088.py:34: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup2 = BeautifulSoup(html,'html')\n"
     ]
    }
   ],
   "source": [
    "#contains link to each webpage containing an image\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "master_list = []\n",
    "count = 0;\n",
    "session = requests.Session()\n",
    "\n",
    "# loops throught the website's sitemaps\n",
    "for loc in soup.find_all('loc') :\n",
    "\n",
    "    \n",
    "    url = loc.text\n",
    "    \n",
    "    # this will limit the number of images to be downloaded\n",
    "    to_continue = len(master_list) <= max_number_of_images\n",
    "    if to_continue and max_number_of_images > 0 :\n",
    "        print(url)\n",
    "    else:\n",
    "        break \n",
    "\n",
    "    # This is to ensure a connection with the website is maintained\n",
    "    try:\n",
    "        response3 = session.get(url)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    response2 = requests.get(url)\n",
    "    html = response2.text\n",
    "    soup2 = BeautifulSoup(html,'html')\n",
    "\n",
    "    # This is to make sure we have access to this specific page\n",
    "    if response2.status_code > 199 and response2.status_code < 400:\n",
    "        # loops through each link in this sitemap\n",
    "        for loc2 in soup2.find_all('loc'):\n",
    "            url2 = loc2.text\n",
    "            master_list.append(url2)\n",
    "\n",
    "            # This is to keep count of images to download and stop when the target number has been reached\n",
    "            to_continue = len(master_list) <= max_number_of_images\n",
    "            if to_continue and max_number_of_images > 0 :\n",
    "                count += 1\n",
    "            else:\n",
    "                break \n",
    "                \n",
    "            \n",
    "            # This will stop you from a big mistake\n",
    "            if max_number_of_images == -1:\n",
    "                import sys\n",
    "                answer = ' '\n",
    "                while answer != 'Yes':\n",
    "                    print('All images will be download')\n",
    "                    print('Warning this will be many Gigabyttes')\n",
    "                    print('Do You want to proceed? ')\n",
    "                    answer = input('Yes/No: WARNINGN: ONLY THESE ANSWERS WILL BE ACCEPTED')\n",
    "                    print('If you answered \\'Yes\\', the program will run as requested')\n",
    "                    print('If you answered \\'No\\', the program will stop and you will need to run it from the very begining to used again')\n",
    "                    if answer == 'No':\n",
    "                        sys.exit('User Terminated Program')\n",
    "                        break\n",
    "            \n",
    "                \n",
    "       \n",
    "        \n",
    "\n",
    "# this cell creates a list that contains the download link for each image\n",
    "image_link_list = []\n",
    "for image_url in master_list[1:]:\n",
    "    response3 = requests.get(image_url)\n",
    "    soup3 = BeautifulSoup(response3.text,'html')\n",
    "    #print(soup3)\n",
    "    link2 = soup3.find('a',{'class': 'download'})\n",
    "    image_link = link2.get('href')\n",
    "    image_link_list.append(image_link)\n",
    "    \n",
    "\n",
    "# This cell will export the images to current working directory\n",
    "# Each image will have a unique name and the last numbers at the end of each image serve as a serial number\n",
    "suffix = 0\n",
    "for png in image_link_list:\n",
    "\n",
    "    image = requests.get(png)\n",
    "    image_name = png.split('/')[-1]\n",
    "    image_name = image_name[0:-4] + '-' + str(suffix)\n",
    "    suffix += 1\n",
    "    \n",
    "\n",
    "    with open(image_name,'wb') as file:\n",
    "        file.write(image.content)\n",
    "print('Congrats you have downloaded ', count, ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547e94a-5268-4165-b462-dbdf0cfd5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the end of the project. \n",
    "# Please do not use this project and it's contents to abuse any website, database, or anything similar.\n",
    "# Please do not commit any crimes using this project and it's content\n",
    "# Please understand running this project will take up space on your computer.\n",
    "# Please understand this project was made for educational purposes \n",
    "# Please understand I do not accept responsibility and/or liability for any parties's damages by the use of this project and it's contents, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d5b2f-03ff-464c-891d-0fc98b58f072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
